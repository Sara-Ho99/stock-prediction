{
 "cells": [
  {
   "cell_type": "code",
   "id": "e2335a3b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T23:51:34.925037Z",
     "start_time": "2024-07-04T23:51:34.918037Z"
    }
   },
   "source": [
    "# 0. Import all libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "import tensorflow as tf\n"
   ],
   "outputs": [],
   "execution_count": 78
  },
  {
   "cell_type": "code",
   "id": "c6ddb23b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T23:51:34.962859Z",
     "start_time": "2024-07-04T23:51:34.927402Z"
    }
   },
   "source": [
    "# 1. Import data\n",
    "# Close prices + Other prices + Volumes\n",
    "file_path = './data/SMCI.csv'\n",
    "data_price = pd.read_csv(file_path)\n",
    "\n",
    "# Interest rates\n",
    "file_path_IR = './data/IR_daily.csv'\n",
    "data_IR = pd.read_csv(file_path_IR)\n"
   ],
   "outputs": [],
   "execution_count": 79
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T23:51:34.977200Z",
     "start_time": "2024-07-04T23:51:34.964731Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Data CLeaning\n",
    "\n",
    "# Price data\n",
    "# Remove dollar signs and convert to float for specified columns\n",
    "columns_to_convert = ['Close/Last', 'Open', 'High', 'Low']\n",
    "for column in columns_to_convert:\n",
    "    data_price[column] = data_price[column].str.replace('$', '').str.replace(',', '').astype(float)\n",
    "\n",
    "\n",
    "\n",
    "# # Interest Rate Data\n",
    "# # 处理DPRIME列中的缺失数据\n",
    "# for idx, value in data_IR['DPRIME'].items():\n",
    "#     if value == '.':\n",
    "#         # 寻找上一格和下一格的索引\n",
    "#         if idx > 0:\n",
    "#             prev_idx = idx - 1\n",
    "#         else:\n",
    "#             prev_idx = idx\n",
    "#         \n",
    "#         if idx < len(data_IR) - 1:\n",
    "#             next_idx = idx + 1\n",
    "#         else:\n",
    "#             next_idx = idx\n",
    "#         \n",
    "#         # 计算平均值并填充\n",
    "#         if data_IR.at[prev_idx, 'DPRIME'] != '.' and data_IR.at[next_idx, 'DPRIME'] != '.':\n",
    "#             avg_value = (float(data_IR.at[prev_idx, 'DPRIME']) + float(data_IR.at[next_idx, 'DPRIME'])) / 2\n",
    "#             formatted_avg_value = f'{avg_value:.2f}'\n",
    "#             data_IR.at[idx, 'DPRIME'] = formatted_avg_value\n"
   ],
   "id": "e1cd7af61e54730b",
   "outputs": [],
   "execution_count": 80
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T23:51:34.992757Z",
     "start_time": "2024-07-04T23:51:34.979190Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Prepare the complete dataset, called \"merged_data\"\n",
    "\n",
    "# 1. Convert 'Date' columns to datetime\n",
    "data_price['Date'] = pd.to_datetime(data_price['Date'])\n",
    "data_IR['Date'] = pd.to_datetime(data_IR['DATE'])  # 确保 'DATE' 列名正确\n",
    "\n",
    "# # 2. Merge based on 'Date' column\n",
    "# merged_data = pd.merge(data_price, data_IR[['Date', 'DPRIME']], on='Date', how='inner')\n",
    "# \n",
    "# # 3. Print the merged data to check alignment\n",
    "# print(\"Merged Data:\")\n",
    "# print(merged_data.head())\n",
    "# \n",
    "# # 4. Check for any missing data after merge\n",
    "# missing_data = merged_data[merged_data.isnull().any(axis=1)]\n",
    "# if not missing_data.empty:\n",
    "#     print(\"There are rows with mismatched dates:\")\n",
    "#     print(missing_data)\n",
    "# else:\n",
    "#     print(\"All dates in the data are aligned correctly.\")\n"
   ],
   "id": "7c35824e2120a7d0",
   "outputs": [],
   "execution_count": 81
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T23:51:34.996184Z",
     "start_time": "2024-07-04T23:51:34.993686Z"
    }
   },
   "cell_type": "code",
   "source": "merged_data = data_price",
   "id": "410464a4438797ca",
   "outputs": [],
   "execution_count": 82
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T23:51:35.004552Z",
     "start_time": "2024-07-04T23:51:34.996861Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Preparing Data\n",
    "train_set = merged_data[(merged_data['Date'] >= '2014-06-24') & (merged_data['Date'] < '2023-06-24')].copy()\n",
    "valid_set = merged_data[(merged_data['Date'] >= '2023-06-25') & (merged_data['Date'] < '2024-06-21')].copy()"
   ],
   "id": "3b1b81e6cb31a68c",
   "outputs": [],
   "execution_count": 83
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T23:51:35.007391Z",
     "start_time": "2024-07-04T23:51:35.005213Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 2. Setup Variables\n",
    "# 2.1 Time horizon set to be 9 years for training, 1 year for validation\n",
    "# 2.2 time steps for LSTM\n",
    "time_steps = 90     # tested [30, 60, 90, 120], 90 is the most efficient one\n",
    "\n",
    "# 2.3 Feature selection\n",
    "all_features = ['Close/Last', 'Volume', 'Open', 'High', 'Low', 'DPRIME']\n",
    "selected_features = ['Close/Last', 'Volume']\n",
    "# selected_features = ['Close/Last']\n",
    "num_features = len(selected_features)"
   ],
   "id": "c4fdd0a79a1db08d",
   "outputs": [],
   "execution_count": 84
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T23:51:35.017883Z",
     "start_time": "2024-07-04T23:51:35.008485Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 3. Data pre-processing\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "# Normalize the 'Close/Last' column for both training and validation sets\n",
    "train_data = scaler.fit_transform(train_set[selected_features].values)\n",
    "valid_data = scaler.transform(valid_set[selected_features].values)\n",
    "\n",
    "# Initialize lists to store training and validation data\n",
    "# x may contain multiple features, while y is the target value that is being predicted, the close price\n",
    "x_train, y_train = [], []\n",
    "for i in range(time_steps, len(train_data)):\n",
    "    x_train.append(train_data[i-time_steps:i, :])\n",
    "    y_train.append(train_data[i, 0])  # Only keep the Close/Last column as label\n",
    "\n",
    "x_valid, y_valid = [], []\n",
    "for i in range(time_steps, len(valid_data)):\n",
    "    x_valid.append(valid_data[i-time_steps:i, :])\n",
    "    y_valid.append(valid_data[i, 0])  # Only keep the Close/Last column as label\n",
    "\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "x_train, y_train = np.array(x_train), np.array(y_train)\n",
    "x_valid, y_valid = np.array(x_valid), np.array(y_valid)\n",
    "x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], len(selected_features)))\n",
    "x_valid = np.reshape(x_valid, (x_valid.shape[0], x_valid.shape[1], len(selected_features)))"
   ],
   "id": "8d200d27876586e7",
   "outputs": [],
   "execution_count": 85
  },
  {
   "cell_type": "code",
   "id": "8c5c9382",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T23:51:35.022984Z",
     "start_time": "2024-07-04T23:51:35.018597Z"
    }
   },
   "source": [
    "# 4. Build Model - function\n",
    "def build_model():\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=50, return_sequences=True, input_shape=(time_steps, num_features)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(units=50, return_sequences=False))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(units=1))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model"
   ],
   "outputs": [],
   "execution_count": 86
  },
  {
   "cell_type": "code",
   "id": "5db99227",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T23:51:35.026982Z",
     "start_time": "2024-07-04T23:51:35.024855Z"
    }
   },
   "source": [
    "# 5. Training - Function\n",
    "def train_model(model, x_train, y_train):\n",
    "    model.fit(x_train, y_train, epochs=25, batch_size=32)"
   ],
   "outputs": [],
   "execution_count": 87
  },
  {
   "cell_type": "code",
   "id": "a25f0e47",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T23:51:35.030505Z",
     "start_time": "2024-07-04T23:51:35.027686Z"
    }
   },
   "source": [
    "# 6. Make Prediction - Function\n",
    "\n",
    "# @tf.function(reduce_retracing=True)\n",
    "# def make_prediction(model, x_valid):\n",
    "#     return model(x_valid, training=False)\n",
    "\n",
    "\n",
    "def make_prediction(model, x_valid, scaler):\n",
    "    predictions = model.predict(x_valid)\n",
    "    predictions = scaler.inverse_transform(predictions)\n",
    "    return predictions\n"
   ],
   "outputs": [],
   "execution_count": 88
  },
  {
   "cell_type": "code",
   "id": "f32867f6",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-07-04T23:53:18.751140Z",
     "start_time": "2024-07-04T23:51:35.031094Z"
    }
   },
   "source": [
    "# Execute step 4,5,6\n",
    "\n",
    "# model = build_model()\n",
    "# train_model(model, x_train, y_train)\n",
    "# \n",
    "# # 将验证集数据转换为张量\n",
    "# x_valid_tensor = tf.convert_to_tensor(x_valid, dtype=tf.float32)\n",
    "# \n",
    "# # 预测\n",
    "# valid_preds = make_prediction(model, x_valid_tensor)\n",
    "# \n",
    "# # Ensure valid_preds has the correct shape\n",
    "# valid_preds = np.squeeze(valid_preds, axis=-1)\n",
    "\n",
    "\n",
    "\n",
    "model = build_model()\n",
    "train_model(model, x_train, y_train)\n",
    "valid_preds = make_prediction(model, x_valid, scaler)\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/beilinye/Desktop/Spring_2024/SYDE_660a/6_Code/stock-prediction/.venv/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 27ms/step - loss: 0.0012\n",
      "Epoch 2/25\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 27ms/step - loss: 2.1656e-04\n",
      "Epoch 3/25\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 39ms/step - loss: 1.6724e-04\n",
      "Epoch 4/25\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 39ms/step - loss: 1.3017e-04\n",
      "Epoch 5/25\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 32ms/step - loss: 1.3707e-04\n",
      "Epoch 6/25\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 36ms/step - loss: 1.0785e-04\n",
      "Epoch 7/25\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 30ms/step - loss: 1.3073e-04\n",
      "Epoch 8/25\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 35ms/step - loss: 1.3399e-04\n",
      "Epoch 9/25\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 32ms/step - loss: 1.0414e-04\n",
      "Epoch 10/25\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 38ms/step - loss: 1.0596e-04\n",
      "Epoch 11/25\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 51ms/step - loss: 1.2359e-04\n",
      "Epoch 12/25\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 70ms/step - loss: 9.8511e-05\n",
      "Epoch 13/25\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 84ms/step - loss: 9.1039e-05\n",
      "Epoch 14/25\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 47ms/step - loss: 7.3684e-05\n",
      "Epoch 15/25\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 48ms/step - loss: 1.0530e-04\n",
      "Epoch 16/25\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 38ms/step - loss: 8.6262e-05\n",
      "Epoch 17/25\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 190ms/step - loss: 7.6117e-05\n",
      "Epoch 18/25\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 65ms/step - loss: 8.0258e-05\n",
      "Epoch 19/25\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 80ms/step - loss: 7.8802e-05\n",
      "Epoch 20/25\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 49ms/step - loss: 7.7555e-05\n",
      "Epoch 21/25\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 80ms/step - loss: 8.0715e-05\n",
      "Epoch 22/25\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m11s\u001B[0m 156ms/step - loss: 7.9960e-05\n",
      "Epoch 23/25\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 54ms/step - loss: 9.0378e-05\n",
      "Epoch 24/25\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 76ms/step - loss: 9.0242e-05\n",
      "Epoch 25/25\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 60ms/step - loss: 8.2642e-05\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 321ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "non-broadcastable output operand with shape (159,1) doesn't match the broadcast shape (159,2)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[89], line 19\u001B[0m\n\u001B[1;32m     17\u001B[0m model \u001B[38;5;241m=\u001B[39m build_model()\n\u001B[1;32m     18\u001B[0m train_model(model, x_train, y_train)\n\u001B[0;32m---> 19\u001B[0m valid_preds \u001B[38;5;241m=\u001B[39m \u001B[43mmake_prediction\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx_valid\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscaler\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[88], line 10\u001B[0m, in \u001B[0;36mmake_prediction\u001B[0;34m(model, x_valid, scaler)\u001B[0m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mmake_prediction\u001B[39m(model, x_valid, scaler):\n\u001B[1;32m      9\u001B[0m     predictions \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mpredict(x_valid)\n\u001B[0;32m---> 10\u001B[0m     predictions \u001B[38;5;241m=\u001B[39m \u001B[43mscaler\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minverse_transform\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpredictions\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     11\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m predictions\n",
      "File \u001B[0;32m~/Desktop/Spring_2024/SYDE_660a/6_Code/stock-prediction/.venv/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:574\u001B[0m, in \u001B[0;36mMinMaxScaler.inverse_transform\u001B[0;34m(self, X)\u001B[0m\n\u001B[1;32m    564\u001B[0m xp, _ \u001B[38;5;241m=\u001B[39m get_namespace(X)\n\u001B[1;32m    566\u001B[0m X \u001B[38;5;241m=\u001B[39m check_array(\n\u001B[1;32m    567\u001B[0m     X,\n\u001B[1;32m    568\u001B[0m     copy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcopy,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    571\u001B[0m     force_all_finite\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mallow-nan\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    572\u001B[0m )\n\u001B[0;32m--> 574\u001B[0m X \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmin_\n\u001B[1;32m    575\u001B[0m X \u001B[38;5;241m/\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mscale_\n\u001B[1;32m    576\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m X\n",
      "\u001B[0;31mValueError\u001B[0m: non-broadcastable output operand with shape (159,1) doesn't match the broadcast shape (159,2)"
     ]
    }
   ],
   "execution_count": 89
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T23:53:18.753009Z",
     "start_time": "2024-07-04T23:53:18.752935Z"
    }
   },
   "cell_type": "code",
   "source": "print(valid_preds)",
   "id": "c8408583df040f17",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "43e1f87a",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "# 计算验证集上的RMSE\n",
    "valid_rmse = np.sqrt(mean_squared_error(valid_set['Close/Last'].values[time_steps:], valid_preds))\n",
    "print(f\"LSTM RMSE on validation set: {valid_rmse}\")\n",
    "\n",
    "# 可视化LSTM结果\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(train_set['Date'], train_set['Close/Last'], label='Training Data')\n",
    "plt.plot(valid_set['Date'][time_steps:], valid_set['Close/Last'].values[time_steps:], label='Validation Data')\n",
    "plt.plot(valid_set['Date'][time_steps:], valid_preds, label='Validation Predictions')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Stock Price')\n",
    "plt.title('Stock Price Prediction with LSTM')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
