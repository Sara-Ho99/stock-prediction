{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T01:11:07.201182Z",
     "start_time": "2024-07-17T01:11:03.511043Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 0. Import all libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Import data\n",
    "file_path = './data/merged_data.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# # Data Cleaning\n",
    "# columns_to_convert = ['Close/Last', 'Open', 'High', 'Low']\n",
    "# for column in columns_to_convert:\n",
    "#     data[column] = data[column].str.replace('$', '').str.replace(',', '').astype(float)\n",
    "\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "data = data.sort_values(by='Date', ascending=True)\n",
    "train_set = data[(data['Date'] >= '2014-06-24') & (data['Date'] < '2023-02-24')].copy()\n",
    "\n",
    "# 2. Setup Variables\n",
    "time_steps = 90\n",
    "future_steps = 10  # Number of future time steps to predict\n",
    "\n",
    "# 3. Data pre-processing\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "train_data = scaler.fit_transform(train_set['Close/Last'].values.reshape(-1, 1))\n",
    "\n",
    "# Initialize lists to store training data\n",
    "x_train, y_train = [], []\n",
    "for i in range(time_steps, len(train_data) - future_steps + 1):\n",
    "    x_train.append(train_data[i - time_steps:i, 0])\n",
    "    y_train.append(train_data[i:i + future_steps, 0])\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "x_train, y_train = np.array(x_train), np.array(y_train)\n",
    "x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
    "\n",
    "# 4. Build Model\n",
    "def build_model():\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=100, return_sequences=True, input_shape=(time_steps, 1)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(units=100, return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(units=50, return_sequences=False))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(units=future_steps))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# 5. Training\n",
    "def train_model(model, x_train, y_train):\n",
    "    model.fit(x_train, y_train, epochs=50, batch_size=64)\n",
    "\n",
    "# 6. Make Multi-Step Prediction\n",
    "def make_multi_step_prediction(model, data, scaler, future_steps):\n",
    "    last_data = data[-time_steps:]\n",
    "    last_data = np.reshape(last_data, (1, last_data.shape[0], 1))\n",
    "    \n",
    "    predicted_prices = model.predict(last_data)\n",
    "    predicted_prices = scaler.inverse_transform(predicted_prices.reshape(-1, 1))\n",
    "    \n",
    "    return predicted_prices\n",
    "\n",
    "# Execute steps 4, 5, 6\n",
    "model = build_model()\n",
    "train_model(model, x_train, y_train)\n",
    "\n",
    "# Predict future 10 days' Close/Last prices\n",
    "predicted_prices = make_multi_step_prediction(model, train_data, scaler, future_steps=future_steps)\n",
    "\n",
    "# Find the last date in the training set\n",
    "last_date = train_set['Date'].max()\n",
    "print(f\"last_date:{last_date}\")\n",
    "\n",
    "future_dates = []\n",
    "print(f\"Predicted Close Prices for the next {future_steps} days:\")\n",
    "for i, price in enumerate(predicted_prices, 1):\n",
    "    future_date = (last_date + pd.offsets.BDay(i)).strftime('%Y-%m-%d')\n",
    "    future_date = pd.to_datetime(future_date)\n",
    "    future_dates.append(future_date)\n",
    "    print(f\"Day {i} ({future_date}): {price[0]}\")\n",
    "\n",
    "# Plotting function\n",
    "def plot_historical_and_predicted(train_set, predicted_prices, future_dates, future_steps):\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    plt.plot(train_set['Date'], train_set['Close/Last'], label='Historical Close Price')\n",
    "    plt.plot(future_dates, predicted_prices, color='red', label='Predicted Prices')\n",
    "    plt.title(f'Historical Close Price with Predicted Prices for next {future_steps} days')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Price')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "plot_historical_and_predicted(train_set, predicted_prices, future_dates, future_steps=future_steps)\n"
   ],
   "id": "dd36385195147555",
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can only use .str accessor with string values!",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 16\u001B[0m\n\u001B[1;32m     14\u001B[0m columns_to_convert \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mClose/Last\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mOpen\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mHigh\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mLow\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m     15\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m column \u001B[38;5;129;01min\u001B[39;00m columns_to_convert:\n\u001B[0;32m---> 16\u001B[0m     data[column] \u001B[38;5;241m=\u001B[39m \u001B[43mdata\u001B[49m\u001B[43m[\u001B[49m\u001B[43mcolumn\u001B[49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstr\u001B[49m\u001B[38;5;241m.\u001B[39mreplace(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m$\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m'\u001B[39m)\u001B[38;5;241m.\u001B[39mstr\u001B[38;5;241m.\u001B[39mreplace(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m,\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m'\u001B[39m)\u001B[38;5;241m.\u001B[39mastype(\u001B[38;5;28mfloat\u001B[39m)\n\u001B[1;32m     18\u001B[0m data[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mDate\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mto_datetime(data[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mDate\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m     19\u001B[0m data \u001B[38;5;241m=\u001B[39m data\u001B[38;5;241m.\u001B[39msort_values(by\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mDate\u001B[39m\u001B[38;5;124m'\u001B[39m, ascending\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "File \u001B[0;32m~/Desktop/Spring_2024/SYDE_660a/6_Code/stock-prediction/.venv/lib/python3.10/site-packages/pandas/core/generic.py:6299\u001B[0m, in \u001B[0;36mNDFrame.__getattr__\u001B[0;34m(self, name)\u001B[0m\n\u001B[1;32m   6292\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[1;32m   6293\u001B[0m     name \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_internal_names_set\n\u001B[1;32m   6294\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m name \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_metadata\n\u001B[1;32m   6295\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m name \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_accessors\n\u001B[1;32m   6296\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_info_axis\u001B[38;5;241m.\u001B[39m_can_hold_identifiers_and_holds_name(name)\n\u001B[1;32m   6297\u001B[0m ):\n\u001B[1;32m   6298\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m[name]\n\u001B[0;32m-> 6299\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mobject\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__getattribute__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/Spring_2024/SYDE_660a/6_Code/stock-prediction/.venv/lib/python3.10/site-packages/pandas/core/accessor.py:224\u001B[0m, in \u001B[0;36mCachedAccessor.__get__\u001B[0;34m(self, obj, cls)\u001B[0m\n\u001B[1;32m    221\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m obj \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    222\u001B[0m     \u001B[38;5;66;03m# we're accessing the attribute of the class, i.e., Dataset.geo\u001B[39;00m\n\u001B[1;32m    223\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_accessor\n\u001B[0;32m--> 224\u001B[0m accessor_obj \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_accessor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobj\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    225\u001B[0m \u001B[38;5;66;03m# Replace the property with the accessor object. Inspired by:\u001B[39;00m\n\u001B[1;32m    226\u001B[0m \u001B[38;5;66;03m# https://www.pydanny.com/cached-property.html\u001B[39;00m\n\u001B[1;32m    227\u001B[0m \u001B[38;5;66;03m# We need to use object.__setattr__ because we overwrite __setattr__ on\u001B[39;00m\n\u001B[1;32m    228\u001B[0m \u001B[38;5;66;03m# NDFrame\u001B[39;00m\n\u001B[1;32m    229\u001B[0m \u001B[38;5;28mobject\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__setattr__\u001B[39m(obj, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_name, accessor_obj)\n",
      "File \u001B[0;32m~/Desktop/Spring_2024/SYDE_660a/6_Code/stock-prediction/.venv/lib/python3.10/site-packages/pandas/core/strings/accessor.py:191\u001B[0m, in \u001B[0;36mStringMethods.__init__\u001B[0;34m(self, data)\u001B[0m\n\u001B[1;32m    188\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, data) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    189\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcore\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01marrays\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mstring_\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m StringDtype\n\u001B[0;32m--> 191\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_inferred_dtype \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_validate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    192\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_is_categorical \u001B[38;5;241m=\u001B[39m \u001B[38;5;28misinstance\u001B[39m(data\u001B[38;5;241m.\u001B[39mdtype, CategoricalDtype)\n\u001B[1;32m    193\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_is_string \u001B[38;5;241m=\u001B[39m \u001B[38;5;28misinstance\u001B[39m(data\u001B[38;5;241m.\u001B[39mdtype, StringDtype)\n",
      "File \u001B[0;32m~/Desktop/Spring_2024/SYDE_660a/6_Code/stock-prediction/.venv/lib/python3.10/site-packages/pandas/core/strings/accessor.py:245\u001B[0m, in \u001B[0;36mStringMethods._validate\u001B[0;34m(data)\u001B[0m\n\u001B[1;32m    242\u001B[0m inferred_dtype \u001B[38;5;241m=\u001B[39m lib\u001B[38;5;241m.\u001B[39minfer_dtype(values, skipna\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m    244\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m inferred_dtype \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m allowed_types:\n\u001B[0;32m--> 245\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCan only use .str accessor with string values!\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    246\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m inferred_dtype\n",
      "\u001B[0;31mAttributeError\u001B[0m: Can only use .str accessor with string values!"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "data",
   "id": "73d312762f843077",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# 可视化各特征之间的关联性\n",
    "correlation_matrix = data.corr()\n",
    "plt.figure(figsize=(16, 10))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')\n",
    "plt.title('Feature Correlation Matrix')\n",
    "plt.show()"
   ],
   "id": "19e5ee7628f8c354",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 生成滞后特征\n",
    "lags = 5\n",
    "for lag in range(1, lags + 1):\n",
    "    data[f'Close_Lag_{lag}'] = data['Close/Last'].shift(lag)\n",
    "    data[f'Open_Lag_{lag}'] = data['Open'].shift(lag)\n",
    "    data[f'High_Lag_{lag}'] = data['High'].shift(lag)\n",
    "    data[f'Low_Lag_{lag}'] = data['Low'].shift(lag)\n",
    "    data[f'Volume_Lag_{lag}'] = data['Volume'].shift(lag)\n",
    "\n",
    "# 丢弃包含 NaN 的行\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "# 计算滞后特征与当前 Close/Last 的相关性\n",
    "correlation_matrix = data[[f'Close_Lag_{lag}' for lag in range(1, lags + 1)] +\n",
    "                          [f'Open_Lag_{lag}' for lag in range(1, lags + 1)] +\n",
    "                          [f'High_Lag_{lag}' for lag in range(1, lags + 1)] +\n",
    "                          [f'Low_Lag_{lag}' for lag in range(1, lags + 1)] +\n",
    "                          [f'Volume_Lag_{lag}' for lag in range(1, lags + 1)] +\n",
    "                          ['Close/Last']].corr()\n",
    "\n",
    "# 只显示滞后特征与当前 Close/Last 的相关性\n",
    "plt.figure(figsize=(16, 10))\n",
    "sns.heatmap(correlation_matrix[['Close/Last']], annot=True, cmap='coolwarm')\n",
    "plt.title('Lagged Features Correlation with Close/Last')\n",
    "plt.show()\n"
   ],
   "id": "b008c9e559a43a59",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
