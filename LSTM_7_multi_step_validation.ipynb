{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T22:18:26.340317Z",
     "start_time": "2024-07-15T22:18:26.181562Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 0. Import all libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Import data\n",
    "file_path = './data/merged_data.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "data = data.sort_values(by='Date', ascending=True)\n",
    "\n",
    "# train_set = data[(data['Date'] >= '2014-06-24') & (data['Date'] < '2023-06-24')].copy()\n",
    "# valid_set = data[(data['Date'] >= '2022-06-25') & (data['Date'] <= '2024-06-21')].copy()\n",
    "\n",
    "\n",
    "total_length = len(data)\n",
    "train_length = int(total_length * 0.8)\n",
    "train_set = data.iloc[:train_length].copy()\n",
    "valid_set = data.iloc[train_length:].copy()\n",
    "\n",
    "\n",
    "# print(\"Training set date range:\", train_set['Date'].min(), \"to\", train_set['Date'].max())\n",
    "# print(\"Validation set date range:\", valid_set['Date'].min(), \"to\", valid_set['Date'].max())\n",
    "\n",
    "\n",
    "\n",
    "# 2. Setup Variables\n",
    "time_steps = 90\n",
    "future_steps = 10  # Number of future time steps to predict\n",
    "\n",
    "# 3. Data pre-processing\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "train_data = scaler.fit_transform(train_set['Close/Last'].values.reshape(-1, 1))\n",
    "valid_data = scaler.transform(valid_set['Close/Last'].values.reshape(-1, 1))\n",
    "\n",
    "# Create training and testing dataset\n",
    "def create_dataset(data, time_steps, future_steps):\n",
    "    x, y = [], []\n",
    "    for i in range(time_steps, len(data) - future_steps + 1):\n",
    "        x.append(data[i - time_steps:i, 0])\n",
    "        y.append(data[i:i + future_steps, 0])\n",
    "    return np.array(x), np.array(y)\n",
    "\n",
    "x_train, y_train = create_dataset(train_data, time_steps, future_steps)\n",
    "x_validation, y_validation = create_dataset(valid_data, time_steps, future_steps)\n",
    "\n",
    "# Reshape for LSTM input\n",
    "x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
    "x_validation = np.reshape(x_validation, (x_validation.shape[0], x_validation.shape[1], 1))\n",
    "\n",
    "\n",
    "# 调整y_train的形状以匹配模型输出\n",
    "y_train = np.reshape(y_train, (y_train.shape[0], future_steps, 1))\n",
    "\n",
    "\n",
    "\n",
    "# 4. Build Model\n",
    "def build_model():\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=50, return_sequences=True, input_shape=(time_steps, 1)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(units=50, return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    # model.add(LSTM(units=50, return_sequences=False))\n",
    "    # model.add(Dropout(0.2))\n",
    "    model.add(Dense(units=future_steps))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# 5. Training\n",
    "def train_model(model, x_train, y_train):\n",
    "    model.fit(x_train, y_train, epochs=25, batch_size=32)\n",
    "\n",
    "# 6. Make Multi-Step Prediction\n",
    "def make_multi_step_prediction(model, x_valid, scaler):\n",
    "    # last_data = data[-time_steps:]\n",
    "    # last_data = np.reshape(last_data, (1, last_data.shape[0], 1))\n",
    "    # \n",
    "    predicted_y_valid_normalized = model.predict(x_valid)\n",
    "    predicted_y_valid = scaler.inverse_transform(predicted_y_valid_normalized.reshape(-1, 1))\n",
    "    return predicted_y_valid\n",
    "\n",
    "# Execute steps 4, 5, 6\n",
    "model = build_model()\n",
    "train_model(model, x_train, y_train)\n",
    "\n",
    "# Predict future 10 days' Close/Last prices\n",
    "predicted_y_valid = make_multi_step_prediction(model, x_validation, scaler)\n",
    "\n",
    "# Find the last date in the training set\n",
    "last_date = train_set['Date'].max()\n",
    "print(f\"last_date:{last_date}\")\n",
    "\n",
    "future_dates = []\n",
    "print(f\"Predicted Close Prices for the next {future_steps} days:\")\n",
    "for i, price in enumerate(predicted_y_valid, 1):\n",
    "    future_date = (last_date + pd.offsets.BDay(i+1)).strftime('%Y-%m-%d')\n",
    "    future_date = pd.to_datetime(future_date)\n",
    "    future_dates.append(future_date)\n",
    "    print(f\"Day {i+1} ({future_date}): {predicted_y_valid[0][i]}\")\n",
    "\n",
    "\n",
    "# Plotting function\n",
    "def plot_historical_and_predicted(train_set, predicted_prices, future_dates, future_steps):\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    plt.plot(train_set['Date'], train_set['Close/Last'], label='Historical Close Price')\n",
    "    plt.plot(future_dates, predicted_prices, color='red', label='Predicted Prices')\n",
    "    plt.title(f'Historical Close Price with Predicted Prices for next {future_steps} days')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Price')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "plot_historical_and_predicted(train_set, predicted_y_valid, future_dates, future_steps=future_steps)\n"
   ],
   "id": "dd36385195147555",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/beilinye/Desktop/Spring_2024/SYDE_660a/6_Code/stock-prediction/.venv/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Dimensions must be equal, but are 10 and 90 for '{{node compile_loss/mean_squared_error/sub}} = Sub[T=DT_FLOAT](data_1, sequential_4_1/dense_4_1/Add)' with input shapes: [?,10,1], [?,90,10].",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 89\u001B[0m\n\u001B[1;32m     87\u001B[0m \u001B[38;5;66;03m# Execute steps 4, 5, 6\u001B[39;00m\n\u001B[1;32m     88\u001B[0m model \u001B[38;5;241m=\u001B[39m build_model()\n\u001B[0;32m---> 89\u001B[0m \u001B[43mtrain_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     91\u001B[0m \u001B[38;5;66;03m# Predict future 10 days' Close/Last prices\u001B[39;00m\n\u001B[1;32m     92\u001B[0m predicted_y_valid \u001B[38;5;241m=\u001B[39m make_multi_step_prediction(model, x_validation, scaler)\n",
      "Cell \u001B[0;32mIn[5], line 76\u001B[0m, in \u001B[0;36mtrain_model\u001B[0;34m(model, x_train, y_train)\u001B[0m\n\u001B[1;32m     75\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mtrain_model\u001B[39m(model, x_train, y_train):\n\u001B[0;32m---> 76\u001B[0m     \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m25\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m32\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/Spring_2024/SYDE_660a/6_Code/stock-prediction/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    119\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[1;32m    120\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[1;32m    121\u001B[0m     \u001B[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001B[39;00m\n\u001B[0;32m--> 122\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    123\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    124\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[0;32m~/Desktop/Spring_2024/SYDE_660a/6_Code/stock-prediction/.venv/lib/python3.10/site-packages/keras/src/losses/losses.py:1286\u001B[0m, in \u001B[0;36mmean_squared_error\u001B[0;34m(y_true, y_pred)\u001B[0m\n\u001B[1;32m   1284\u001B[0m y_true \u001B[38;5;241m=\u001B[39m ops\u001B[38;5;241m.\u001B[39mconvert_to_tensor(y_true, dtype\u001B[38;5;241m=\u001B[39my_pred\u001B[38;5;241m.\u001B[39mdtype)\n\u001B[1;32m   1285\u001B[0m y_true, y_pred \u001B[38;5;241m=\u001B[39m squeeze_or_expand_to_same_rank(y_true, y_pred)\n\u001B[0;32m-> 1286\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m ops\u001B[38;5;241m.\u001B[39mmean(ops\u001B[38;5;241m.\u001B[39msquare(\u001B[43my_true\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[43m \u001B[49m\u001B[43my_pred\u001B[49m), axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n",
      "\u001B[0;31mValueError\u001B[0m: Dimensions must be equal, but are 10 and 90 for '{{node compile_loss/mean_squared_error/sub}} = Sub[T=DT_FLOAT](data_1, sequential_4_1/dense_4_1/Add)' with input shapes: [?,10,1], [?,90,10]."
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "data",
   "id": "73d312762f843077",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
